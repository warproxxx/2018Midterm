{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from casIn.user_influence import P,influence\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "\n",
    "class timeout:\n",
    "    def __init__(self, seconds=1, error_message='Timeout'):\n",
    "        self.seconds = seconds\n",
    "        self.error_message = error_message\n",
    "    def handle_timeout(self, signum, frame):\n",
    "        raise TimeoutError(self.error_message)\n",
    "    def __enter__(self):\n",
    "        signal.signal(signal.SIGALRM, self.handle_timeout)\n",
    "        signal.alarm(self.seconds)\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.alarm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('cascade_with_influence.csv')\n",
    "cascades = pd.read_csv('metrics_retweet_cascade.csv')\n",
    "\n",
    "tweets = tweets[['User', 'Time', 'followers_count']]\n",
    "tweets = tweets.rename(columns={'Time': 'time', 'followers_count': 'magnitude', 'User': 'user_id'})\n",
    "\n",
    "possible_cascade_size = cascades['size'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_actual = pd.DataFrame(columns=['user_id', 'sample', 'actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_actual['user_id'] = tweets['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_actual = sample_actual.set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_actual['sample'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_actual['actual'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_inf(df):\n",
    "        return pd.Series({'total':sum(df['inf'])})\n",
    "\n",
    "def get_influence(df):\n",
    "    p_ij = P(df,r = -0.000068)\n",
    "    \n",
    "    with timeout(seconds=300):\n",
    "        try:\n",
    "            inf, m_ij = influence(p_ij)\n",
    "            df['inf'] = inf\n",
    "        except:\n",
    "            df['inf'] = 0\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cascades = 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "for i in range(total_cascades):    \n",
    "    curr_cascade_size = np.random.choice(possible_cascade_size) * 100\n",
    "\n",
    "    actual_cascade = tweets.sample(curr_cascade_size).reset_index(drop=True)\n",
    "\n",
    "    sample_cascade = actual_cascade.sample(frac=0.01).reset_index(drop=True)\n",
    "\n",
    "    actual_influence = get_influence(actual_cascade)\n",
    "\n",
    "    sample_influence = get_influence(sample_cascade)\n",
    "\n",
    "    userwise_actual = actual_influence.groupby('user_id').apply(get_total_inf)\n",
    "\n",
    "    userwise_sample = sample_influence.groupby('user_id').apply(get_total_inf)\n",
    "\n",
    "    sample_actual = sample_actual.join(userwise_actual)\n",
    "    sample_actual['total'] = sample_actual['total'].fillna(0)\n",
    "    sample_actual['actual'] = sample_actual['actual'] + sample_actual['total']\n",
    "    sample_actual = sample_actual.drop('total', axis=1)\n",
    "\n",
    "    sample_actual = sample_actual.join(userwise_sample)\n",
    "    sample_actual['total'] = sample_actual['total'].fillna(0)\n",
    "    sample_actual['sample'] = sample_actual['sample'] + sample_actual['total']\n",
    "    sample_actual = sample_actual.drop('total', axis=1)\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96, 0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(sample_actual['sample'],sample_actual['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:meta_analyse]",
   "language": "python",
   "name": "conda-env-meta_analyse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
