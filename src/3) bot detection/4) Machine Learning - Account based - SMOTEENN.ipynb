{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "w\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_standardize = ['friends_count', 'statuses_count', 'listed_count', 'followers_count', 'favourites_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(AL, y, verbose=1):\n",
    "    \n",
    "    try:\n",
    "        AL = np.array(AL)\n",
    "        y = np.array(y)\n",
    "\n",
    "        AL = AL.reshape(-1)\n",
    "        y = y.reshape(-1)\n",
    "\n",
    "        AL = AL > 0.5\n",
    "        AL = AL.astype(int)\n",
    "\n",
    "        y = y > 0.5\n",
    "        y = y.astype(int)\n",
    "        \n",
    "        auc = roc_auc_score(y, AL)\n",
    "\n",
    "        total = AL.shape[0]\n",
    "\n",
    "        TP = np.sum(np.logical_and(AL==1, y==1))\n",
    "        TN = np.sum(np.logical_and(AL==0, y==0))\n",
    "\n",
    "        FP = np.sum(np.logical_and(AL==1, y==0))\n",
    "        FN = np.sum(np.logical_and(AL==0, y==1))\n",
    "\n",
    "        P = TP / (TP + FP)\n",
    "        R = TP / (TP + FN)\n",
    "        F1 = (2 * P * R) / (P + R)\n",
    "\n",
    "\n",
    "        acc = np.sum(AL == y)/total\n",
    "\n",
    "\n",
    "        if verbose == 1:\n",
    "            print(\"\\nAccuracy: {} \\n\".format(acc))\n",
    "            print(\"AUC: {}\".format(auc))\n",
    "            print(\"True Positive: {} \\nTrue Negative: {}\\nFalse Positive: {} \\nFalse Negative: {}\\n\".format(TP, TN, FP, FN))\n",
    "            print(\"Precision: {} \\nRecall: {} \\nF1 Score: {}\\n\".format(P, R, F1))\n",
    "        \n",
    "        return acc\n",
    "    except:\n",
    "        return 0\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    Returns:\n",
    "    ________\n",
    "    \n",
    "    df (pandas dataframe):\n",
    "    Dataframe containing userinfo\n",
    "    \n",
    "    users_bots (pandas dataframe):\n",
    "    dataframe containing score from botometer\n",
    "    '''\n",
    "    \n",
    "    users_bots = pd.read_csv('username_botometer.csv')\n",
    "    df = pd.read_csv('../../data/new_profiles_cleaned.csv')\n",
    "    election_accounts = pd.read_csv('../../data/collection_data/profile/extractedUsers.csv')\n",
    "    election_accounts.columns = ['username']\n",
    "\n",
    "    election_accounts['username'] = election_accounts['username'].str.lower()\n",
    "    df['username'] = df['username'].str.lower()\n",
    "    users_bots['username'] = users_bots['username'].str.lower()\n",
    "    \n",
    "    users_bots = users_bots[users_bots['username'].isin(election_accounts['username'])].reset_index(drop=True)\n",
    "    df = df[df['username'].isin(election_accounts['username'])].reset_index(drop=True)\n",
    "    \n",
    "    return df, users_bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, users_bots = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44580, 12)\n",
      "(26475, 11)\n",
      "(1394, 11)\n"
     ]
    }
   ],
   "source": [
    "users_bots = pd.read_csv('username_botometer.csv')\n",
    "users_bots['username'] = users_bots['username'].str.lower()\n",
    "training_df = pd.read_csv('training_set.csv')\n",
    "\n",
    "non_training_df = users_bots[~users_bots['username'].isin(training_df['username'])].reset_index(drop=True)\n",
    "non_training_df = non_training_df.merge(df).drop_duplicates('username').reset_index(drop=True)\n",
    "print(non_training_df.shape)\n",
    "\n",
    "training_df = training_df.drop('username', axis=1)\n",
    "print(training_df.shape)\n",
    "\n",
    "test_df = pd.read_csv('test_set.csv').drop('username', axis=1)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df_mean = training_df[columns_to_standardize].mean()\n",
    "training_df_std = training_df[columns_to_standardize].std()\n",
    "\n",
    "training_df[columns_to_standardize] = (training_df[columns_to_standardize] - training_df_mean)/training_df_std\n",
    "test_df[columns_to_standardize] = (test_df[columns_to_standardize] - training_df_mean)/training_df_std\n",
    "non_training_df[columns_to_standardize] = (non_training_df[columns_to_standardize] - training_df_mean)/training_df_std\n",
    "\n",
    "\n",
    "X_train = training_df.drop(['BotOrNot'], axis=1).values\n",
    "y_train = training_df['BotOrNot'].values.reshape(-1,1)\n",
    "\n",
    "X_test = test_df.drop(['BotOrNot'], axis=1).values\n",
    "y_test = test_df['BotOrNot'].values.reshape(-1,1)\n",
    "\n",
    "X_non = non_training_df.drop(['username', 'botometer'], axis=1).values\n",
    "y_non = non_training_df['botometer'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df_mean.to_csv('mean.csv')\n",
    "training_df_std.to_csv('std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=150, random_state=0)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = SMOTE()\n",
    "smote_X, smote_y = s.fit_resample(X_train, y_train.reshape(-1))\n",
    "\n",
    "e = EditedNearestNeighbours()\n",
    "r_X, r_y = e.fit_resample(smote_X, smote_y)\n",
    "\n",
    "a = AdaBoostClassifier(n_estimators=150, random_state=0)\n",
    "\n",
    "a.fit(r_X, r_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_X, r_y = X_train, y_train.reshape(-1)\n",
    "# a = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "# a.fit(r_X, r_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = a.predict(r_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.855826678199996 \n",
      "\n",
      "AUC: 0.8545674252215391\n",
      "True Positive: 19618 \n",
      "True Negative: 22926\n",
      "False Positive: 3059 \n",
      "False Negative: 4108\n",
      "\n",
      "Precision: 0.8651056136173215 \n",
      "Recall: 0.8268566129983984 \n",
      "F1 Score: 0.8455487791737604\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.855826678199996"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(y_predict, r_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = a.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8773314203730272 \n",
      "\n",
      "AUC: 0.7452668632860813\n",
      "True Positive: 14 \n",
      "True Negative: 1209\n",
      "False Positive: 162 \n",
      "False Negative: 9\n",
      "\n",
      "Precision: 0.07954545454545454 \n",
      "Recall: 0.6086956521739131 \n",
      "F1 Score: 0.1407035175879397\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8773314203730272"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(y_test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_training_predict = a.predict(X_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8544638851502916 \n",
      "\n",
      "AUC: 0.788356421032658\n",
      "True Positive: 664 \n",
      "True Negative: 37428\n",
      "False Positive: 6229 \n",
      "False Negative: 259\n",
      "\n",
      "Precision: 0.09632960974902074 \n",
      "Recall: 0.7193932827735645 \n",
      "F1 Score: 0.1699078812691914\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8544638851502916"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(non_training_predict, (y_non > 0.5).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def predict_all(df, best_model, training_df_mean, training_df_std):\n",
    "#     '''\n",
    "#     Parameters:\n",
    "#     ___________\n",
    "#     df (pandas dataframe):\n",
    "#     Dataframe containing userinfo \n",
    "    \n",
    "#     best_model (model):\n",
    "#    a Keras model that turned out best\n",
    "    \n",
    "#     training_df_mean (float)\n",
    "#     training_df_std (float)\n",
    "    \n",
    "    \n",
    "#     Returns:\n",
    "#     ________\n",
    "#     df_with_predictions (Dataframe with predictions from the best model)\n",
    "#     '''\n",
    "#     global columns_to_standardize\n",
    "    \n",
    "#     df[columns_to_standardize] = (df[columns_to_standardize] - training_df_mean)/training_df_std\n",
    "#     df_as_X = df.drop('username', axis=1).values\n",
    "#     predicted_df = best_model.predict(df_as_X)\n",
    "    \n",
    "#     df['predicted'] = predicted_df\n",
    "#     print(\"The percentage of bots is: {}\".format((sum(df['predicted'] > 0.5)/len(df)) * 100))\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[columns_to_standardize] = (df[columns_to_standardize] - training_df_mean)/training_df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted'] = a.predict(df.drop('username', axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274875"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.408225858974456"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(df['predicted'])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[columns_to_standardize] = ((df[columns_to_standardize] * training_df_std)+  training_df_mean).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('profiles_with_bot_or_not.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'bot_detection.sav'\n",
    "pickle.dump(a, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
