{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense, Dense, Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from multiprocessing.pool import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_standardize = ['friends_count', 'statuses_count', 'listed_count', 'followers_count', 'favourites_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_accuracy(AL, y, verbose=1):\n",
    "    \n",
    "    try:\n",
    "        AL = np.array(AL)\n",
    "        y = np.array(y)\n",
    "\n",
    "        AL = AL.reshape(-1)\n",
    "        y = y.reshape(-1)\n",
    "\n",
    "        AL = AL > 0.5\n",
    "        AL = AL.astype(int)\n",
    "\n",
    "        y = y > 0.5\n",
    "        y = y.astype(int)\n",
    "\n",
    "        total = AL.shape[0]\n",
    "\n",
    "        TP = np.sum(np.logical_and(AL==1, y==1))\n",
    "        TN = np.sum(np.logical_and(AL==0, y==0))\n",
    "\n",
    "        FP = np.sum(np.logical_and(AL==1, y==0))\n",
    "        FN = np.sum(np.logical_and(AL==0, y==1))\n",
    "\n",
    "        P = TP / (TP + FP)\n",
    "        R = TP / (TP + FN)\n",
    "        F1 = (2 * P * R) / (P + R)\n",
    "\n",
    "\n",
    "        acc = np.sum(AL == y)/total\n",
    "\n",
    "\n",
    "        if verbose == 1:\n",
    "            print(\"\\nAccuracy: {} \\n\".format(acc))\n",
    "            print(\"True Positive: {} \\nTrue Negative: {}\\nFalse Positive: {} \\nFalse Negative: {}\\n\".format(TP, TN, FP, FN))\n",
    "            print(\"Precision: {} \\nRecall: {} \\nF1 Score: {}\\n\".format(P, R, F1))\n",
    "        \n",
    "        return acc\n",
    "    except:\n",
    "        return 0\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    Returns:\n",
    "    ________\n",
    "    \n",
    "    df (pandas dataframe):\n",
    "    Dataframe containing userinfo\n",
    "    \n",
    "    users_bots (pandas dataframe):\n",
    "    dataframe containing score from botometer\n",
    "    '''\n",
    "    \n",
    "    users_bots = pd.read_csv('username_botometer.csv')\n",
    "    df = pd.read_csv('../../data/new_profiles_cleaned.csv')\n",
    "    election_accounts = pd.read_csv('../../data/collection_data/profile/extractedUsers.csv')\n",
    "    election_accounts.columns = ['username']\n",
    "\n",
    "    election_accounts['username'] = election_accounts['username'].str.lower()\n",
    "    df['username'] = df['username'].str.lower()\n",
    "    users_bots['username'] = users_bots['username'].str.lower()\n",
    "    \n",
    "    users_bots = users_bots[users_bots['username'].isin(election_accounts['username'])].reset_index(drop=True)\n",
    "    df = df[df['username'].isin(election_accounts['username'])].reset_index(drop=True)\n",
    "    \n",
    "    return df, users_bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, users_bots = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2640940, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_threshold(users_bots, bot_threshold, user_threshold):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ___________\n",
    "    \n",
    "    users_bots (pandas dataframe):\n",
    "    Dataframe containing username and botometer score\n",
    "    \n",
    "    bot_threshold (float):\n",
    "    Threshold above which we will classify as bot during training\n",
    "    \n",
    "    user_threshold (float):\n",
    "    Threshold below which we will classify as humans during training\n",
    "    \n",
    "    Returns:\n",
    "    ________\n",
    "    bot_accounts, clean_accounts\n",
    "    '''\n",
    "    bot_accounts = users_bots[users_bots['botometer'] > bot_threshold].reset_index(drop=True)\n",
    "    clean_accounts = users_bots[users_bots['botometer'] < user_threshold].reset_index(drop=True)\n",
    "    return bot_accounts, clean_accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_test(df, bot_accounts, clean_accounts, ratio, verbose=1):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ___________\n",
    "    df (pandas dataframe):\n",
    "    Dataframe containing user info\n",
    "    \n",
    "    bot_accounts (dataframe)\n",
    "    \n",
    "    clean_accounts (dataframe) \n",
    "    \n",
    "    ratio (int):\n",
    "    How many clean accounts per bot accounts\n",
    "    '''\n",
    "    \n",
    "    #Remove any duplicates if they exist here but this function is too big\n",
    "    bot_details = df[df['username'].isin(bot_accounts['username'])]\n",
    "    bot_details = bot_details.reset_index(drop=True)\n",
    "\n",
    "    clean_details = df[df['username'].isin(clean_accounts['username'])]\n",
    "    clean_details = clean_details.reset_index(drop=True)\n",
    "    clean_details = clean_details[:int(bot_details.shape[0] * ratio)]\n",
    "\n",
    "    bot_details['BotOrNot'] = 1\n",
    "    clean_details['BotOrNot'] = 0\n",
    "\n",
    "    combined_df = clean_details.append(bot_details, ignore_index=True)\n",
    "\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print(\"Combined Details: {}\".format(combined_df.shape))\n",
    "        print(\"Bot Details: {}\".format(bot_details.shape))\n",
    "        print(\"Clean Details: {}\".format(clean_details.shape))\n",
    "\n",
    "    new_df = combined_df.sample(frac=1).reset_index(drop=True)\n",
    "    bot_df = new_df[new_df['BotOrNot'] == 1].reset_index(drop=True)\n",
    "    human_df = new_df[new_df['BotOrNot'] == 0]\n",
    "    new_df = pd.concat([bot_df, human_df]).reset_index(drop=True)\n",
    "    new_df = new_df.sample(frac=1).reset_index(drop=True)\n",
    "    to_see = users_bots[~users_bots['username'].isin(combined_df['username'])].reset_index(drop=True)\n",
    "    comparision_df = df[df['username'].isin(to_see['username'])]\n",
    "    test_df = pd.merge(comparision_df, to_see,on=\"username\")\n",
    "    test_df['botometer'] = (test_df['botometer'] > 0.5).astype(int)\n",
    "    \n",
    "    total_bots = sum(test_df['botometer'] > 0.5)\n",
    "    test_df = pd.concat([test_df[test_df['botometer'] == 0][:total_bots], test_df[test_df['botometer'] == 1]]).reset_index(drop=True)\n",
    "    \n",
    "    training_df = new_df.drop('username', axis=1)\n",
    "    test_df = test_df.drop('username', axis=1)\n",
    "\n",
    "    global columns_to_standardize\n",
    "\n",
    "    training_df_mean = training_df[columns_to_standardize].mean()\n",
    "    training_df_std = training_df[columns_to_standardize].std()\n",
    "\n",
    "    training_df[columns_to_standardize] = (training_df[columns_to_standardize] - training_df_mean)/training_df_std\n",
    "    test_df[columns_to_standardize] = (test_df[columns_to_standardize] - training_df_mean)/training_df_std\n",
    "    X_train = training_df.drop(['BotOrNot'], axis=1).values\n",
    "    y_train = training_df['BotOrNot'].values.reshape(-1,1)\n",
    "\n",
    "    X_test = test_df.drop(['botometer'], axis=1).values\n",
    "    y_test = test_df['botometer'].values.reshape(-1,1)\n",
    "    \n",
    "    return training_df_mean, training_df_std, X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perform_all(df, users_bots, bot_threshold, human_threshold, ratio, verbose=1):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ___________\n",
    "    df (pandas dataframe):\n",
    "    Dataframe containing userinfo\n",
    "    \n",
    "    users_bots (pandas dataframe):\n",
    "    dataframe containing score from botometer\n",
    "    \n",
    "    bot_threshold (float):\n",
    "    Threshold above which we will classify as bot during training\n",
    "    \n",
    "    human_threshold (float):\n",
    "    Threshold below which we will classify as humans during training\n",
    "    \n",
    "    ratio (int):\n",
    "    How many clean accounts per bot accounts\n",
    "    \n",
    "    verbose (int):\n",
    "    Display output and debug information if set to 1, dosen't if set to 0\n",
    "    \n",
    "    Returns:\n",
    "    ________\n",
    "    val_acc (float):\n",
    "    accuracy of the validation set\n",
    "    \n",
    "    train_acc (float:)\n",
    "    accuracy of the training set\n",
    "    \n",
    "    best_model (model):\n",
    "    Keras model that turned out best\n",
    "    \n",
    "    training_df_mean (float)\n",
    "    training_df_std (float)\n",
    "    '''\n",
    "    \n",
    "    bot_accounts, clean_accounts = apply_threshold(users_bots, bot_threshold, human_threshold)\n",
    "\n",
    "    training_df_mean, training_df_std, X_train, y_train, X_test, y_test = get_training_test(df, bot_accounts, clean_accounts, ratio, verbose=verbose)\n",
    "\n",
    "    inp = Input(shape=[10])\n",
    "\n",
    "    another = Dense(500, activation='relu')(inp)\n",
    "    another = Dense(200, activation='relu')(another)\n",
    "    another = Dense(1, activation='sigmoid')(another)\n",
    "\n",
    "    mod = Model(inp, another)\n",
    "\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=verbose, patience=200)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=verbose, save_best_only=True)\n",
    "\n",
    "    mod.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    mod.fit(x=X_train, y=y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test), callbacks=[es, mc], verbose=verbose)\n",
    "\n",
    "    best_model = load_model('best_model.h5')\n",
    "\n",
    "    ytrain_mod = best_model.predict(X_train)\n",
    "    train_acc = get_accuracy(ytrain_mod, y_train, verbose=verbose)\n",
    "\n",
    "\n",
    "    ytest_mod = best_model.predict(X_test)\n",
    "    val_acc = get_accuracy(ytest_mod, y_test, verbose=verbose)\n",
    "    return val_acc, train_acc, best_model, training_df_mean, training_df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_hyperparameters():\n",
    "    global df\n",
    "    global users_bots\n",
    "    bot_threshold = [0.39, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    human_threshold = [0.4, 0.3, 0.2, 0.15, 0.1, 0.05]\n",
    "    ratios = [1, 2]\n",
    "    results = pd.DataFrame(columns=['bot', 'human', 'ratio', 'val_acc', 'train_acc'])\n",
    "\n",
    "    i = 1\n",
    "    total = len(bot_threshold) * len(human_threshold) * len(ratios)\n",
    "\n",
    "    for bot in bot_threshold:\n",
    "        for human in human_threshold:\n",
    "            for ratio in ratios:\n",
    "                print(\"{} of {}\".format(i, total))\n",
    "                val_acc, train_acc, best_model, training_df_mean, training_df_std = perform_all(df, users_bots, bot, human, ratio, verbose=0)            \n",
    "\n",
    "                currentResult = pd.Series({'bot': bot, 'human': human, 'ratio': ratio, 'val_acc': val_acc, 'train_acc': train_acc})\n",
    "                results = results.append(currentResult, ignore_index=True)\n",
    "                results.to_csv('current_results.csv', index=None)\n",
    "                i = i + 1\n",
    "                \n",
    "# find_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv('current_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results['val_train_avg'] = (results['val_acc'] + results['train_acc'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_all(df, best_model, training_df_mean, training_df_std):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ___________\n",
    "    df (pandas dataframe):\n",
    "    Dataframe containing userinfo \n",
    "    \n",
    "    best_model (model):\n",
    "    Keras model that turned out best\n",
    "    \n",
    "    training_df_mean (float)\n",
    "    training_df_std (float)\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    ________\n",
    "    df_with_predictions (Dataframe with predictions from the best model)\n",
    "    '''\n",
    "    global columns_to_standardize\n",
    "    \n",
    "    df[columns_to_standardize] = (df[columns_to_standardize] - training_df_mean)/training_df_std\n",
    "    df_as_X = df.drop('username', axis=1).values\n",
    "    predicted_df = best_model.predict(df_as_X)\n",
    "    \n",
    "    df['predicted'] = predicted_df\n",
    "    print(\"The percentage of bots is: {}\".format((sum(df['predicted'] > 0.5)/len(df)) * 100))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for idx, config in results.sort_values('val_train_avg', ascending=False)[:10].iterrows():\n",
    "    \n",
    "#     print(config)\n",
    "#     val_acc, train_acc, best_model, training_df_mean, training_df_std = perform_all(df, users_bots, config['bot'], config['human'], config['ratio'])\n",
    "#     df_with_predictions = predict_all(df, best_model, training_df_mean, training_df_std)\n",
    "    \n",
    "#     try:\n",
    "#         df = df.drop('predicted', axis=1)\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Details: (3844, 12)\n",
      "Bot Details: (1922, 12)\n",
      "Clean Details: (1922, 12)\n",
      "Train on 3844 samples, validate on 12780 samples\n",
      "Epoch 1/20\n",
      "3844/3844 [==============================] - 1s 262us/step - loss: 0.3525 - acc: 0.8522 - val_loss: 0.7981 - val_acc: 0.7032\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70321, saving model to best_model.h5\n",
      "Epoch 2/20\n",
      "3844/3844 [==============================] - 0s 81us/step - loss: 0.2843 - acc: 0.8827 - val_loss: 0.7882 - val_acc: 0.7016\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.70321\n",
      "Epoch 3/20\n",
      "3844/3844 [==============================] - 0s 88us/step - loss: 0.2716 - acc: 0.8850 - val_loss: 0.8400 - val_acc: 0.7040\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.70321 to 0.70399, saving model to best_model.h5\n",
      "Epoch 4/20\n",
      "3844/3844 [==============================] - 0s 84us/step - loss: 0.2709 - acc: 0.8866 - val_loss: 0.8080 - val_acc: 0.7074\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.70399 to 0.70743, saving model to best_model.h5\n",
      "Epoch 5/20\n",
      "3844/3844 [==============================] - 0s 82us/step - loss: 0.2589 - acc: 0.8965 - val_loss: 0.7825 - val_acc: 0.7137\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.70743 to 0.71369, saving model to best_model.h5\n",
      "Epoch 6/20\n",
      "3844/3844 [==============================] - 0s 80us/step - loss: 0.2549 - acc: 0.8944 - val_loss: 0.8127 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.71369\n",
      "Epoch 7/20\n",
      "3844/3844 [==============================] - 0s 87us/step - loss: 0.2559 - acc: 0.8944 - val_loss: 0.8168 - val_acc: 0.7131\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.71369\n",
      "Epoch 8/20\n",
      "3844/3844 [==============================] - 0s 99us/step - loss: 0.2511 - acc: 0.8965 - val_loss: 0.8169 - val_acc: 0.7138\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.71369 to 0.71377, saving model to best_model.h5\n",
      "Epoch 9/20\n",
      "3844/3844 [==============================] - 0s 84us/step - loss: 0.2406 - acc: 0.9022 - val_loss: 0.8145 - val_acc: 0.7077\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.71377\n",
      "Epoch 10/20\n",
      "3844/3844 [==============================] - 0s 83us/step - loss: 0.2394 - acc: 0.9017 - val_loss: 0.8037 - val_acc: 0.7159\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.71377 to 0.71588, saving model to best_model.h5\n",
      "Epoch 11/20\n",
      "3844/3844 [==============================] - 0s 84us/step - loss: 0.2354 - acc: 0.9035 - val_loss: 0.8448 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.71588 to 0.71995, saving model to best_model.h5\n",
      "Epoch 12/20\n",
      "3844/3844 [==============================] - 0s 81us/step - loss: 0.2363 - acc: 0.9048 - val_loss: 0.7847 - val_acc: 0.7112\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.71995\n",
      "Epoch 13/20\n",
      "3844/3844 [==============================] - 0s 84us/step - loss: 0.2353 - acc: 0.9032 - val_loss: 0.7762 - val_acc: 0.7134\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.71995\n",
      "Epoch 14/20\n",
      "3844/3844 [==============================] - 0s 105us/step - loss: 0.2205 - acc: 0.9084 - val_loss: 0.8707 - val_acc: 0.7231\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.71995 to 0.72308, saving model to best_model.h5\n",
      "Epoch 15/20\n",
      "3844/3844 [==============================] - 0s 96us/step - loss: 0.2298 - acc: 0.9063 - val_loss: 0.7818 - val_acc: 0.7214\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.72308\n",
      "Epoch 16/20\n",
      "3844/3844 [==============================] - 0s 98us/step - loss: 0.2278 - acc: 0.9069 - val_loss: 0.8197 - val_acc: 0.7118\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.72308\n",
      "Epoch 17/20\n",
      "3844/3844 [==============================] - 0s 100us/step - loss: 0.2263 - acc: 0.9082 - val_loss: 0.8280 - val_acc: 0.7163\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.72308\n",
      "Epoch 18/20\n",
      "3844/3844 [==============================] - 0s 93us/step - loss: 0.2273 - acc: 0.9102 - val_loss: 0.7852 - val_acc: 0.7201\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.72308\n",
      "Epoch 19/20\n",
      "3844/3844 [==============================] - 0s 94us/step - loss: 0.2162 - acc: 0.9152 - val_loss: 0.8111 - val_acc: 0.7194\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.72308\n",
      "Epoch 20/20\n",
      "3844/3844 [==============================] - 0s 94us/step - loss: 0.2201 - acc: 0.9118 - val_loss: 0.7912 - val_acc: 0.7185\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.72308\n",
      "\n",
      "Accuracy: 0.9102497398543185 \n",
      "\n",
      "True Positive: 1738 \n",
      "True Negative: 1761\n",
      "False Positive: 161 \n",
      "False Negative: 184\n",
      "\n",
      "Precision: 0.9152185360716166 \n",
      "Recall: 0.9042663891779397 \n",
      "F1 Score: 0.9097095001308558\n",
      "\n",
      "\n",
      "Accuracy: 0.7230829420970266 \n",
      "\n",
      "True Positive: 4480 \n",
      "True Negative: 4761\n",
      "False Positive: 1629 \n",
      "False Negative: 1910\n",
      "\n",
      "Precision: 0.7333442461941398 \n",
      "Recall: 0.701095461658842 \n",
      "F1 Score: 0.7168573485878871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = df.drop('predicted', axis=1)\n",
    "except:\n",
    "    pass\n",
    "val_acc, train_acc, best_model, training_df_mean, training_df_std = perform_all(df, users_bots, 0.75, 0.15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of bots is: 31.557589343188408\n"
     ]
    }
   ],
   "source": [
    "df_with_predictions = predict_all(df, best_model, training_df_mean, training_df_std)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
