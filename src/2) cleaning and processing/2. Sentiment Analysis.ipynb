{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import csv\n",
    "import nltk\n",
    "import statistics\n",
    "import subprocess\n",
    "import shlex\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import swifter\n",
    "from itertools import zip_longest\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/all_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('vader_lexicon')\n",
    "s = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nlp = StanfordCoreNLP('../../data/stanford-corenlp-full-2018-10-05/')\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "anew = \"lib/EnglishShortened.csv\"\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "#source https://github.com/dwzhou/SentimentAnalysis/blob/master/src/AnewSentimentAnalysis.py\n",
    "def valence_arousal_dominance(fulltext):\n",
    "    \"\"\"\n",
    "    Performs sentiment analysis on the text file given as input using the ANEW database.\n",
    "    Outputs results to a new CSV file in output_dir.\n",
    "    :param fulltext: text to analyze\n",
    "    :return: v_score, a_score, d_score\n",
    "    \"\"\"\n",
    "    sentences = tokenize.sent_tokenize(fulltext)\n",
    "    i = 1\n",
    "    \n",
    "    total_words = 0\n",
    "    v_score = 0\n",
    "    a_score = 0\n",
    "    d_score = 0\n",
    "    found_words = []\n",
    "    \n",
    "    for s in sentences:\n",
    "        # search for each valid word's sentiment in ANEW\n",
    "        words = nlp.pos_tag(s.lower())\n",
    "        for index, p in enumerate(words):\n",
    "            # don't process stops or words w/ punctuation\n",
    "            w = p[0]\n",
    "            pos = p[1]\n",
    "            if w in stops or not w.isalpha():\n",
    "                continue\n",
    "\n",
    "            # check for negation in 3 words before current word\n",
    "            j = index-1\n",
    "            neg = False\n",
    "            while j >= 0 and j >= index-3:\n",
    "                if words[j][0] == 'not' or words[j][0] == 'no' or words[j][0] == 'n\\'t':\n",
    "                    neg = True\n",
    "                    break\n",
    "                j -= 1\n",
    "\n",
    "            # lemmatize word based on pos\n",
    "            if pos[0] == 'N' or pos[0] == 'V':\n",
    "                lemma = lmtzr.lemmatize(w, pos=pos[0].lower())\n",
    "            else:\n",
    "                lemma = w\n",
    "            \n",
    "            with open(anew) as csvfile:\n",
    "                reader = csv.DictReader(csvfile)\n",
    "                for row in reader:\n",
    "                    if row['Word'].casefold() == lemma.casefold():\n",
    "                        if neg:\n",
    "                            found_words.append(\"neg-\"+lemma)\n",
    "                        else:\n",
    "                            found_words.append(lemma)\n",
    "                        v = float(row['valence'])\n",
    "                        a = float(row['arousal'])\n",
    "                        d = float(row['dominance'])\n",
    "\n",
    "                        if neg:\n",
    "                            # reverse polarity for this word\n",
    "                            v = 5 - (v - 5)\n",
    "                            a = 5 - (a - 5)\n",
    "                            d = 5 - (d - 5)\n",
    "\n",
    "                        v_score = v_score + v\n",
    "                        a_score = a_score + a\n",
    "                        d_score = d_score + d\n",
    "\n",
    "    if len(found_words) != 0:  # no words found in ANEW for this sentence\n",
    "        v_score = v_score/len(found_words)\n",
    "        a_score = a_score/len(found_words)\n",
    "        d_score = d_score/len(found_words)\n",
    "            \n",
    "    \n",
    "    return v_score, a_score, d_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#too slow don't do this\n",
    "# val_a_d = df['Tweet'].progress_apply(valence_arousal_dominance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#can make this much efficient\n",
    "def perform_sentiment_analysis(x):\n",
    "    x = str(x)\n",
    "    vader_emotion = s.polarity_scores(x)['compound']\n",
    "    sen = TextBlob(x).sentiment\n",
    "    polarity = sen.polarity\n",
    "    subjectivity = sen.subjectivity\n",
    "    \n",
    "    return vader_emotion, polarity, subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 7039259/7039259 [2:10:11<00:00, 901.18it/s]\n"
     ]
    }
   ],
   "source": [
    "emotions = df['Tweet'].swifter.apply(perform_sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emotions_df=pd.DataFrame(emotions.tolist(), columns=['vader_emotion', 'polarity', 'subjectivity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.join(emotions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['Tweet'] = df['Tweet'].fillna(\"NA\")\n",
    "\n",
    "# df['Tweet'] = df['Tweet'].replace(r'\\\\n',' ', regex=True) \n",
    "# df['Tweet'] = df['Tweet'].replace(r'\\n',' ', regex=True) \n",
    "\n",
    "# df['Tweet'] = df['Tweet'].replace(r'\\\\r',' ', regex=True) \n",
    "# df['Tweet'] = df['Tweet'].replace(r'\\r',' ', regex=True) \n",
    "\n",
    "# df['Tweet'] = df['Tweet'].replace(r'\\\\t',' ', regex=True) \n",
    "# df['Tweet'] = df['Tweet'].replace(r'\\t',' ', regex=True) \n",
    "\n",
    "# df['Tweet'].to_csv('tweets', index=None, header=None)\n",
    "\n",
    "# java -jar SentiStrength.jar sentidata SentiStrength_Data/ input tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = pd.read_csv('tweets0_out.txt', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.join(aa[['Positive', 'Negative']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../../data/all_cleaned.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
